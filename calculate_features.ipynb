{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open dataframe containing user acceleration data (in world coordinate frame). Calculate interesting features, and pickle the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as pl\n",
    "import peakutils\n",
    "from peakutils.plot import plot as pplot\n",
    "\n",
    "from scipy import signal, ndimage, io, stats\n",
    "import scipy.integrate as integrate\n",
    "from math import factorial\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sampling interval and frequency\n",
    "samplingint = 0.01\n",
    "Fs = 1/samplingint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifiable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ENTER FILENAME!\n",
    "filename = 'Accelerometer_Demographics_df'\n",
    "\n",
    "thresholdingparam = 1.5\n",
    "peakfindinterval = 80\n",
    "\n",
    "minnumpeaksfound = 5\n",
    "maxnumpeaksfound = 20\n",
    "numpeakintervalstoavg = 5\n",
    "\n",
    "maxpoweratrest = 0.00005\n",
    "\n",
    "FFTsamples = 1024\n",
    "minsignallength = 1200\n",
    "\n",
    "RESTFFTsamples = 512\n",
    "RESTminsignallength = 515\n",
    "\n",
    "# buffer for epochs between steps\n",
    "buff = 5\n",
    "minchunksamples = 90\n",
    "\n",
    "Accelerometer_df = pd.read_pickle(filename)\n",
    "recordnums = Accelerometer_df.index # important - some indices won't be there since we dropped records before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Savitzky Golay Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Savitzky Golay filter from http://scipy.github.io/old-wiki/pages/Cookbook/SavitzkyGolay\n",
    "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
    "    try:\n",
    "        window_size = np.abs(np.int(window_size))\n",
    "        order = np.abs(np.int(order))\n",
    "    except ValueError, msg:\n",
    "        raise ValueError(\"window_size and order have to be of type int\")\n",
    "    if window_size % 2 != 1 or window_size < 1:\n",
    "        raise TypeError(\"window_size size must be a positive odd number\")\n",
    "    if window_size < order + 2:\n",
    "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
    "    order_range = range(order+1)\n",
    "    half_window = (window_size -1) // 2\n",
    "    # precompute coefficients\n",
    "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
    "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
    "    # pad the signal at the extremes with values taken from the signal itself\n",
    "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
    "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
    "    y = np.concatenate((firstvals, y, lastvals))\n",
    "    return np.convolve( m[::-1], y, mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_FFT(timeseries, samplingint):\n",
    "    fouriercoefficients = np.fft.rfft(timeseries)\n",
    "    normalization = 2.0/len(timeseries)\n",
    "    fouriercoefficients = fouriercoefficients*normalization\n",
    "    frequencies = np.fft.rfftfreq(len(timeseries),samplingint)\n",
    "    return frequencies, fouriercoefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Find Peaks using PeakUtils threshold based peak finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_peak_info(timesignal,processedsignal,sampling_int,thresholdingparam,peakfindinterval):\n",
    "    AVGsignal = np.mean(processedsignal)\n",
    "    minthreshold = thresholdingparam*AVGsignal\n",
    "    peakindices = peakutils.indexes(processedsignal ,thres=minthreshold,min_dist=peakfindinterval)\n",
    "    peaktimes = peakindices*sampling_int\n",
    "    peakamplitudes = timesignal[peakindices]\n",
    "    \n",
    "    return peakindices, peaktimes, peakamplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load record from dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize dataframe for storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureinfo = {'healthCode':[],'record':[],'age':[],'gender':[],'professional-diagnosis':[],'recordId':[],\n",
    "               'totpowerX':[],'totpowerY':[],'totpowerZ':[],\n",
    "               'powentropyX':[], 'powentropyY':[],'powentropyZ':[],\n",
    "               'numpeaksX':[],'numpeaksY':[],'numpeaksZ':[],\n",
    "               'MEANpeakintX':[],'MEANpeakintY':[],'MEANpeakintZ':[],\n",
    "               'CVpeakintX':[],'CVpeakintY':[],'CVpeakintZ':[],'duration':[],\n",
    "               'FFT1Z':[],'FFT2Z':[],'FFT3Z':[],\n",
    "               'modeFFT1chunksX':[], 'SDFFT1chunksX':[], 'modeFFT2chunksX':[],'SDFFT2chunksX':[], 'modeFFT3chunksX':[], 'SDFFT3chunksX':[],\n",
    "               'meanpowchunksX':[],'CVpowchunksX':[],'meanentropychunksX':[],'CVentropychunksX':[],\n",
    "               'modeFFT1chunksY':[], 'SDFFT1chunksY':[],'modeFFT2chunksY':[], 'SDFFT2chunksY':[], 'modeFFT3chunksY':[], 'SDFFT3chunksY':[],\n",
    "               'meanpowchunksY':[],'CVpowchunksY':[],'meanentropychunksY':[],'CVentropychunksY':[],\n",
    "               'modeFFT1chunksZ':[], 'SDFFT1chunksZ':[], 'modeFFT2chunksZ':[], 'SDFFT2chunksZ':[], 'modeFFT3chunksZ':[], 'SDFFT3chunksZ':[],\n",
    "               'meanpowchunksZ':[],'CVpowchunksZ':[],'meanentropychunksZ':[],'CVentropychunksZ':[],\n",
    "               'onset_lag':[],'sumabs_acceleration':[]}\n",
    "\n",
    "feature_df = pd.DataFrame(featureinfo,columns =['healthCode','record','age', 'gender','professional-diagnosis','recordId',\n",
    "                                                'totpowerX','totpowerY','totpowerZ',\n",
    "                                                'powentropyX','powentropyY','powentropyZ',\n",
    "                                                'numpeaksX','numpeaksY','numpeaksZ',\n",
    "                                                'MEANpeakintX','MEANpeakintY','MEANpeakintZ',\n",
    "                                                'CVpeakintX','CVpeakintY','CVpeakintZ',\n",
    "                                                'duration','FFT1Z','FFT2Z','FFT3Z',\n",
    "                                                'modeFFT1chunksX','modeFFT2chunksX','SDFFT1chunksX', 'SDFFT2chunksX', 'modeFFT3chunksX', 'SDFFT3chunksX', \n",
    "                                                'meanpowchunksX','CVpowchunksX','meanentropychunksX','CVentropychunksX',\n",
    "                                                'modeFFT1chunksY', 'SDFFT1chunksY', 'modeFFT2chunksY', 'SDFFT2chunksY', 'modeFFT3chunksY', 'SDFFT3chunksY',\n",
    "                                                'meanpowchunksY','CVpowchunksY','meanentropychunksY','CVentropychunksY',\n",
    "                                                'modeFFT1chunksZ', 'SDFFT1chunksZ','modeFFT2chunksZ', 'SDFFT2chunksZ', 'modeFFT3chunksZ', 'SDFFT3chunksZ', \n",
    "                                                'meanpowchunksZ','CVpowchunksZ','meanentropychunksZ','CVentropychunksZ',\n",
    "                                                'onset_lag','sumabs_acceleration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to calculate features for the recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featuregrabber(record,signame,sig,datamat,datamat_YSG,datamat_processed,samplingint,thresholdingparam,peakfindinterval,minsignallength,minnumpeaksfound,buff):\n",
    "    \n",
    "    # initialize lists for storing calculations for each epoch or \"chunk\" between steps\n",
    "    FFT1chunks = []\n",
    "    FFT2chunks = []\n",
    "    FFT3chunks = []\n",
    "    powerchunks = []\n",
    "    entropychunks = []\n",
    "    \n",
    "    # calculate the duration of the recording\n",
    "    duration = (len(datamat[sig]))*samplingint\n",
    "    \n",
    "    # take recordings that are longer than the minimal length\n",
    "    if len(datamat[sig]) >= minsignallength:\n",
    "        [peakindices, peaktimes, peakamplitudes] = get_peak_info(datamat[sig],datamat_processed[sig],samplingint,thresholdingparam,peakfindinterval)\n",
    "        stepintervals = np.diff(peaktimes)\n",
    "        numpeaks = len(peakindices)\n",
    "\n",
    "        # take recordings where the number of peaks discovered is within the desired range\n",
    "        if numpeaks > minnumpeaksfound and numpeaks <= maxnumpeaksfound:\n",
    "            onset_lag = peakindices[0]*samplingint\n",
    "            for k in np.arange(numpeaks-2):\n",
    "                peakstart = peakindices[k]+buff\n",
    "                peakend = peakindices[k+1]-buff\n",
    "                chunklen = peakend-peakstart\n",
    "                midchunk = peakstart+int(chunklen/2)\n",
    "                if chunklen > minchunksamples:\n",
    "                    chunk = datamat_YSG[sig][midchunk-(minchunksamples/2):midchunk+(minchunksamples/2)]\n",
    "                    fYSG_chunk,Pxx_denYSG_chunk = signal.welch(chunk, Fs)#nperseg=128)\n",
    "                    \n",
    "                    freqchunk, ffcoeffchunk = get_FFT(chunk,samplingint)\n",
    "                    ffcoeffchunk = np.absolute(ffcoeffchunk)**2\n",
    "            \n",
    "                    ff_chunkdf = pd.DataFrame({'fouriercoefficients':ffcoeffchunk,'frequencies':freqchunk})\n",
    "                    ff_chunkdf=ff_chunkdf.sort_values('fouriercoefficients',ascending = False)\n",
    "            \n",
    "                    if ff_chunkdf.iloc[0]['frequencies'] != 0:\n",
    "                        FFT1chunks.append(ff_chunkdf.iloc[0]['frequencies'])\n",
    "                        FFT2chunks.append(ff_chunkdf.iloc[1]['frequencies'])\n",
    "                        FFT3chunks.append(ff_chunkdf.iloc[2]['frequencies'])\n",
    "                        totchunkpower = np.trapz(Pxx_denYSG_chunk)\n",
    "\n",
    "                        entropychunk = stats.entropy(Pxx_denYSG_chunk/totchunkpower)\n",
    "                        powerchunks.append(totchunkpower)\n",
    "                        entropychunks.append(entropychunk)\n",
    "                        \n",
    "            \n",
    "            # take a central part of the recording (same length for all recordings), and calculate frequency spectrum features\n",
    "            midsignal = int(len(datamat_YSG[sig])/2)\n",
    "            FFTsignal = datamat_YSG[sig][(midsignal-FFTsamples/2):(midsignal+FFTsamples/2)]\n",
    "            \n",
    "            f,Pow = signal.welch(FFTsignal, Fs,scaling='density')\n",
    "            totpower = np.trapz(Pow)\n",
    "            powentropy = stats.entropy(Pow/totpower)\n",
    "            \n",
    "   \n",
    "            frequencies, fouriercoefficients = get_FFT(FFTsignal,samplingint)\n",
    "            fouriercoefficients = np.absolute(fouriercoefficients)**2\n",
    "            ff_df = pd.DataFrame({'fouriercoefficients':fouriercoefficients,'frequencies':frequencies})\n",
    "            ff_df = ff_df.sort_values('fouriercoefficients',ascending = False)\n",
    "        \n",
    "            if ff_df.iloc[0]['frequencies'] != 0:\n",
    "                FFT1 = ff_df.iloc[0]['frequencies']\n",
    "                FFT2 = ff_df.iloc[1]['frequencies']\n",
    "                FFT3 = ff_df.iloc[2]['frequencies']\n",
    "            \n",
    "            else:\n",
    "                FFT1 = float('nan')\n",
    "                FFT2 = float('nan')\n",
    "                FFT3 = float('nan')\n",
    "        else:\n",
    "            onset_lag = float('nan')\n",
    "            totpower = float('nan')\n",
    "            powentropy = float('nan')\n",
    "            FFT1 = float('nan')\n",
    "            FFT2 = float('nan')\n",
    "            FFT3 = float('nan')\n",
    "     \n",
    "    else:\n",
    "        numpeaks = float('nan')\n",
    "        stepintervals = float('nan')\n",
    "        totpower = float('nan')\n",
    "        powentropy = float('nan')\n",
    "        FFT1 = float('nan')\n",
    "        FFT2 = float('nan')\n",
    "        FFT3 = float('nan')\n",
    "        onset_lag = float('nan')\n",
    "        \n",
    "    return duration, onset_lag, numpeaks, stepintervals, totpower, powentropy, FFT1, FFT2, FFT3, FFT1chunks, FFT2chunks, FFT3chunks, powerchunks, entropychunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to calculate features within epochs or \"chunks\" between steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunkstats(FFT1chunks, FFT2chunks, FFT3chunks, powerchunks, entropychunks):\n",
    "    if len(FFT1chunks)>=1:\n",
    "        modeFFT1chunks = mode(FFT1chunks)[0][0]\n",
    "        meanpowchunks = np.mean(powerchunks)\n",
    "        SDFFT1chunks = np.std(FFT1chunks)\n",
    "        CVpowchunks = np.std(powerchunks) / meanpowchunks\n",
    "        meanentropychunks = np.mean(entropychunks)\n",
    "        CVentropychunks = np.std(entropychunks) / meanentropychunks\n",
    "        \n",
    "    else:\n",
    "        modeFFT1chunks = float('nan')  \n",
    "        meanpowchunks = float('nan')\n",
    "        SDFFT1chunks = float('nan')\n",
    "        CVpowchunks = float('nan')\n",
    "        meanentropychunks = float('nan')\n",
    "        CVentropychunks = float('nan')\n",
    "        \n",
    "    if len(FFT2chunks)>=1:\n",
    "        modeFFT2chunks = mode(FFT2chunks)[0][0]\n",
    "        SDFFT2chunks = np.std(FFT2chunks)\n",
    "        \n",
    "    else:\n",
    "        modeFFT2chunks = float('nan')  \n",
    "        SDFFT2chunks = float('nan')\n",
    "        \n",
    "            \n",
    "    if len(FFT3chunks)>=1:\n",
    "        modeFFT3chunks = mode(FFT3chunks)[0][0]\n",
    "        SDFFT3chunks = np.std(FFT3chunks)\n",
    "        \n",
    "    else:\n",
    "        modeFFT3chunks = float('nan')  \n",
    "        SDFFT3chunks = float('nan')\n",
    "        \n",
    "    return modeFFT1chunks, SDFFT1chunks, modeFFT2chunks, SDFFT2chunks, modeFFT3chunks, SDFFT3chunks, meanpowchunks,CVpowchunks, meanentropychunks,CVentropychunks  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go through each record in the data frame, calculate features and store in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agata/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:68: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "for record in recordnums:\n",
    "    \n",
    "    ##################################### WALKING DATA ###################################\n",
    "    \n",
    "    time = Accelerometer_df['time'][record]\n",
    "    datamat = np.array([np.asarray(Accelerometer_df['rotX'][record]), np.asarray(Accelerometer_df['rotY'][record]),\n",
    "                        np.asarray(Accelerometer_df['rotZ'][record]), np.asarray(Accelerometer_df['total_rawacceleration'][record])])\n",
    "\n",
    "    axisitems  = np.arange(0,len(datamat))\n",
    "    \n",
    "    # Apply Savitsky Golay filter\n",
    "    datamat_YSG = [savitzky_golay(datamat[myaxis], window_size =51, order=4) for myaxis in axisitems]\n",
    "    \n",
    "    # Apply Savitsky Golay filter to squared signal for peak finding\n",
    "    datamat_YSG_peaks = [savitzky_golay(np.square(datamat[myaxis]), window_size=51, order=4) for myaxis in axisitems]\n",
    "    datamat_processed = datamat_YSG_peaks\n",
    "     \n",
    "    \n",
    "    # X\n",
    "    durationX, onset_lagX, numpeaksX, stepintervalsX, totpowerX, powentropyX, FFT1X, FFT2X, FFT3X, FFT1chunksX, FFT2chunksX, FFT3chunksX, powerchunksX, entropychunksX = featuregrabber(str(record),'X',0,datamat,datamat_YSG,datamat_processed,samplingint,thresholdingparam,peakfindinterval,minsignallength,minnumpeaksfound,buff)\n",
    "    modeFFT1chunksX, SDFFT1chunksX, modeFFT2chunksX, SDFFT2chunksX, modeFFT3chunksX, SDFFT3chunksX, meanpowchunksX,CVpowchunksX,meanentropychunksX,CVentropychunksX  = chunkstats(FFT1chunksX, FFT2chunksX, FFT3chunksX, powerchunksX, entropychunksX)\n",
    "    \n",
    "    \n",
    "    # Y\n",
    "    durationY, onset_lagY, numpeaksY, stepintervalsY, totpowerY, powentropyY, FFT1Y, FFT2Y, FFT3Y, FFT1chunksY, FFT2chunksY, FFT3chunksY, powerchunksY, entropychunksY = featuregrabber(str(record),'Y',1,datamat,datamat_YSG,datamat_processed,samplingint,thresholdingparam,peakfindinterval,minsignallength,minnumpeaksfound,buff)\n",
    "    modeFFT1chunksY, SDFFT1chunksY, modeFFT2chunksY, SDFFT2chunksY, modeFFT3chunksY, SDFFT3chunksY, meanpowchunksY,CVpowchunksY,meanentropychunksY,CVentropychunksY  = chunkstats(FFT1chunksY, FFT2chunksY, FFT3chunksY, powerchunksY, entropychunksY)\n",
    "    \n",
    "\n",
    "    # Z\n",
    "    durationZ, onset_lagZ, numpeaksZ, stepintervalsZ, totpowerZ, powentropyZ, FFT1Z, FFT2Z, FFT3Z, FFT1chunksZ, FFT2chunksZ, FFT3chunksZ, powerchunksZ, entropychunksZ = featuregrabber(str(record),'Z',2,datamat,datamat_YSG,datamat_processed,samplingint,thresholdingparam,peakfindinterval,minsignallength,minnumpeaksfound,buff)\n",
    "    modeFFT1chunksZ, SDFFT1chunksZ, modeFFT2chunksZ, SDFFT2chunksZ, modeFFT3chunksZ, SDFFT3chunksZ, meanpowchunksZ,CVpowchunksZ,meanentropychunksZ,CVentropychunksZ  = chunkstats(FFT1chunksZ, FFT2chunksZ, FFT3chunksZ, powerchunksZ, entropychunksZ)\n",
    "    \n",
    "    \n",
    "    # QUADRATIC SUM OF X,Y,Z\n",
    "    durationSUM, onset_lagSUM,numpeaksSUM, stepintervalsSUM, totpowerSUM, powentropySUM, FFT1SUM, FFT2SUM, FFT3SUM, FFT1chunksSUM, FFT2chunksSUM, FFT3chunksSUM, powerchunksSUM, entropychunksSUM = featuregrabber(str(record),'SUM',3,datamat,datamat_YSG,datamat_processed,samplingint,thresholdingparam,peakfindinterval,minsignallength,minnumpeaksfound,buff)\n",
    "    modeFFT1chunksSUM, SDFFT1chunksSUM, modeFFT2chunksSUM, SDFFT2chunksSUM, modeFFT3chunksSUM, SDFFT3chunksSUM, meanpowchunksSUM,CVpowchunksSUM,meanentropychunksSUM,CVentropychunksSUM = chunkstats(FFT1chunksSUM, FFT2chunksSUM, FFT3chunksSUM, powerchunksSUM, entropychunksSUM)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get metadata for the record\n",
    "    healthCode = Accelerometer_df['healthCode'][record]\n",
    "    age = Accelerometer_df['age'][record]\n",
    "    gender = Accelerometer_df['gender'][record]\n",
    "    professional_diagnosis = Accelerometer_df['professional-diagnosis'][record]\n",
    "    recordId = Accelerometer_df['recordId'][record]\n",
    "    \n",
    "    # Make final feature calculations\n",
    "    MEANpeakintX = np.mean(stepintervalsX)\n",
    "    MEANpeakintY = np.mean(stepintervalsY)\n",
    "    MEANpeakintZ = np.mean(stepintervalsZ)\n",
    "    CVpeakintX = np.std(stepintervalsX) / MEANpeakintX\n",
    "    CVpeakintY = np.std(stepintervalsY) / MEANpeakintY\n",
    "    CVpeakintZ = np.std(stepintervalsZ) / MEANpeakintZ\n",
    "    duration = durationZ\n",
    "    onset_lag = onset_lagZ\n",
    "    sumabs_acceleration = sum(abs(datamat[3]))\n",
    "\n",
    "   \n",
    "    feature_df = feature_df.append({'healthCode':healthCode,'record':record,'age':age, 'gender':gender, 'professional-diagnosis':professional_diagnosis,'recordId':recordId, \n",
    "                                    'totpowerX':totpowerX,'totpowerY':totpowerY,'totpowerZ':totpowerZ,\n",
    "                                    'powentropyX':powentropyX, 'powentropyY':powentropyY,'powentropyZ':powentropyZ,\n",
    "                                    'numpeaksX':numpeaksX,'numpeaksY':numpeaksY,'numpeaksZ':numpeaksZ,\n",
    "                                    'MEANpeakintX':MEANpeakintX,'MEANpeakintY':MEANpeakintY,'MEANpeakintZ':MEANpeakintZ,\n",
    "                                    'CVpeakintX':CVpeakintX,'CVpeakintY':CVpeakintY,'CVpeakintZ':CVpeakintZ,\n",
    "                                    'duration':duration,'FFT1Z':FFT1Z,'FFT2Z':FFT2Z,'FFT3Z':FFT3Z,  \n",
    "                                    'modeFFT1chunksX':modeFFT1chunksX,'SDFFT1chunksX':SDFFT1chunksX,\n",
    "                                    'modeFFT2chunksX':modeFFT2chunksX,'SDFFT2chunksX':SDFFT2chunksX,\n",
    "                                    'modeFFT3chunksX':modeFFT3chunksX,'SDFFT3chunksX':SDFFT3chunksX,\n",
    "                                    'meanpowchunksX':meanpowchunksX,'CVpowchunksX':CVpowchunksX,\n",
    "                                    'meanentropychunksX':meanentropychunksX,'CVentropychunksX':CVentropychunksX,\n",
    "                                    'modeFFT1chunksY':modeFFT1chunksY,'SDFFT1chunksY':SDFFT1chunksY,\n",
    "                                    'modeFFT2chunksY':modeFFT2chunksY,'SDFFT2chunksY':SDFFT2chunksY,\n",
    "                                    'modeFFT3chunksY':modeFFT3chunksY,'SDFFT3chunksY':SDFFT3chunksY,\n",
    "                                    'meanpowchunksY':meanpowchunksY,'CVpowchunksY':CVpowchunksY,\n",
    "                                    'meanentropychunksY':meanentropychunksY,'CVentropychunksY':CVentropychunksY,\n",
    "                                    'modeFFT1chunksZ':modeFFT1chunksZ,'SDFFT1chunksZ':SDFFT1chunksZ,\n",
    "                                    'modeFFT2chunksZ':modeFFT2chunksZ,'SDFFT2chunksZ':SDFFT2chunksZ,\n",
    "                                    'modeFFT3chunksZ':modeFFT3chunksZ,'SDFFT3chunksZ':SDFFT3chunksZ,\n",
    "                                    'meanpowchunksZ':meanpowchunksZ,'CVpowchunksZ':CVpowchunksZ,\n",
    "                                    'meanentropychunksZ':meanentropychunksZ,'CVentropychunksZ':CVentropychunksZ,\n",
    "                                    'onset_lag':onset_lag,'sumabs_acceleration':sumabs_acceleration},ignore_index=True)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove NANs and pickle the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanfeature_df = feature_dfmod.dropna()\n",
    "cleanfeature_df.to_pickle('feature_df')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
